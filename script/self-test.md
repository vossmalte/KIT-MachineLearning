---
title: "Maschinelles Lernen - Grundlagen"
subtitle: "Self-test questions"
author: "Malle \\& Valle"
date: "\\today"
---

## Linear Regression

## Linear classification

## Model selection

## Trees and forests

What we mean with non parametric / instance based machine learning algorithms ?

How k NN works ?

How to choose the k?

Why is it hard to use for high D data ?

How do search for nearest neighbors efficiently ?

What a binary regression / decision tree is

What are useful splitting criterions

How can we influence the model complexity of the tree?

Why is it useful to use multiple trees and randomization?

## Dimensionality Reduction

What does dimensionality reduction mean?

How does linear dimensionality reduction work?

What is PCA? What are the three things that it does?

What are the roles of the Eigenvectors and Eigenvalues in PCA?

Can you describe applications of PCA?

## Clustering

How is the clustering problem defined? Why is it called “unsupervised”?

How do hierarchical clustering methods work? What is the rule of the cluster 2
cluster distance and which distances can we use?

How does the k mean algorithm work? What are the 2 main steps?

Why does the algorithm converge? What is it minimizing?

Does k means finds a the global minimum of the objective?

## Density Estimation and EM

What are parametric methods and how to obtain their parameters?

How many parameters have non parametric methods?

What are mixture models?

Should gradient methods be used for training mixture models?

How does the EM algorithm work?

What is the biggest problem of mixture models?

How does EM decomposes the marginal likelihood?

Why does EM always improve the lower bound?

Why does EM always improve the marginal likelihood

Why can we optimize each mixture component independently with EM

Why do we need sampling for continuous latent variables?
